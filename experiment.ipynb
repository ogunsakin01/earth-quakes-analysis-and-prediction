{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'folium'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mfolium\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfolium\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Choropleth\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfolium\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplugins\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HeatMap\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'folium'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "from folium import Choropleth\n",
    "from folium.plugins import HeatMap\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading EarthQuakes and Tectonic Plates Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "earthquake_data_frame = pd.read_csv('../datasets/earth_quakes_dataset.csv')\n",
    "tectonic_plate_data_frame = pd.read_csv('../datasets/tectonic_plates_dataset.csv')\n",
    "earthquake_data_frame.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tectonic_plate_data_frame.head(100000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning EarthQuakes Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "not_needed_columns_to_drop = ['Depth Error', 'Depth Seismic Stations', 'Magnitude Type', 'Magnitude Error', 'Magnitude Seismic Stations', 'Azimuthal Gap', 'Horizontal Distance', 'Horizontal Error', 'Root Mean Square', 'Source', 'Location Source', 'Magnitude Source', 'Status', 'ID']\n",
    "earthquake_data_frame.drop(not_needed_columns_to_drop, axis=1, inplace=True)\n",
    "earthquake_data_frame.count()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Selecting records with only earthquakes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "earthquake_data_frame = earthquake_data_frame[earthquake_data_frame['Type'] == \"Earthquake\"].reset_index(drop=True)\n",
    "earthquake_data_frame.head(100000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finding bad dates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lengths = earthquake_data_frame[\"Date\"].str.len()\n",
    "lengths.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Viewing found bad dates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_dates = np.where([lengths == 24])[1]\n",
    "print(\"Bad dates:\", bad_dates)\n",
    "earthquake_data_frame.loc[bad_dates]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixing identified bad dates and set date format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "earthquake_data_frame.loc[3359, \"Date\"] = \"02/23/1975\"\n",
    "earthquake_data_frame.loc[7384, \"Date\"] = \"04/28/1985\"\n",
    "earthquake_data_frame.loc[20470, \"Date\"] = \"03/13/2011\"\n",
    "earthquake_data_frame['Date']= pd.to_datetime(earthquake_data_frame[\"Date\"])\n",
    "earthquake_data_frame.info()  #Check date type for changes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Finding bad time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lengths = earthquake_data_frame[\"Time\"].str.len()\n",
    "lengths.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Viewing found bad time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_time = np.where([lengths == 24])[1]\n",
    "print(\"Bad time:\", bad_time)\n",
    "earthquake_data_frame.loc[bad_time]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixing bad time and changing time format"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "earthquake_data_frame.loc[3359, \"Time\"] = \"02:58:41\"\n",
    "earthquake_data_frame.loc[7384, \"Time\"] = \"02:53:41\"\n",
    "earthquake_data_frame.loc[20470, \"Time\"] = \"02:23:34\"\n",
    "earthquake_data_frame['Time']= pd.to_timedelta(earthquake_data_frame['Time'])\n",
    "earthquake_data_frame.info() ##View new type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing Tectonic Plates Boundaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tectonic = folium.Map(tiles=\"cartodbpositron\", zoom_start=5)\n",
    "\n",
    "plates = list(tectonic_plate_data_frame[\"plate\"].unique())\n",
    "for plate in plates:\n",
    "    plate_vals = tectonic_plate_data_frame[tectonic_plate_data_frame[\"plate\"] == plate]\n",
    "    latitudes = plate_vals[\"lat\"].values\n",
    "    longitudes = plate_vals[\"lon\"].values\n",
    "    points = list(zip(latitudes, longitudes))\n",
    "    indexes = [None] + [i + 1 for i, x in enumerate(points) if i < len(points) - 1 and abs(x[1] - points[i + 1][1]) > 300] + [None]\n",
    "    for i in range(len(indexes) - 1):\n",
    "        folium.vector_layers.PolyLine(points[indexes[i]:indexes[i+1]], popup=plate, color=\"#58508d\", fill=False, ).add_to(tectonic)\n",
    "\n",
    "tectonic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
